{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#EDA Tools\n",
    "import pandas_profiling\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "#modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR , LinearSVR\n",
    "\n",
    "\n",
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('CreditScore_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('CreditScore_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 305)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 305)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train_data,test_data],axis='rows',sort=False,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>...</th>\n",
       "      <th>x296</th>\n",
       "      <th>x297</th>\n",
       "      <th>x298</th>\n",
       "      <th>x299</th>\n",
       "      <th>x300</th>\n",
       "      <th>x301</th>\n",
       "      <th>x302</th>\n",
       "      <th>x303</th>\n",
       "      <th>x304</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1084094</td>\n",
       "      <td>426.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1287777</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17318</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1483016</td>\n",
       "      <td>163.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>959054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1342113</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17413</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x001   x002  x003   x004   x005  x006  x007  x008  x009  x010  ...  \\\n",
       "0  1084094  426.0  39.0  128.0  426.0     0     0     0     0     0  ...   \n",
       "1  1287777  160.0   2.0   64.0  160.0     1     1     2     0     1  ...   \n",
       "2  1483016  163.0  16.0  104.0  239.0     0     0     0     1     0  ...   \n",
       "3   959054    NaN   NaN    NaN  102.0     0     0     0     0     0  ...   \n",
       "4  1342113    3.0   2.0    2.0   62.0     0     2     2     0     0  ...   \n",
       "\n",
       "    x296    x297  x298  x299  x300  x301  x302  x303  x304    y  \n",
       "0      0     NaN     0     0     0     0   NaN     0   NaN  807  \n",
       "1  17318  0.8417     1     1     1     0   NaN     0   NaN  819  \n",
       "2      0     NaN     0     0     0     0   NaN     0   NaN  803  \n",
       "3      0     NaN     1     1     1     0   NaN     0   NaN  530  \n",
       "4  17413  1.0180     1     1     1     0   NaN     0   NaN  485  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007', 'x008', 'x009',\n",
       "       'x010',\n",
       "       ...\n",
       "       'x296', 'x297', 'x298', 'x299', 'x300', 'x301', 'x302', 'x303', 'x304',\n",
       "       'y'],\n",
       "      dtype='object', length=305)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 19999\n",
      "Data columns (total 305 columns):\n",
      "x001    100000 non-null int64\n",
      "x002    78568 non-null float64\n",
      "x003    78568 non-null float64\n",
      "x004    78576 non-null float64\n",
      "x005    93890 non-null float64\n",
      "x006    100000 non-null int64\n",
      "x007    100000 non-null int64\n",
      "x008    100000 non-null int64\n",
      "x009    100000 non-null int64\n",
      "x010    100000 non-null int64\n",
      "x011    100000 non-null int64\n",
      "x012    100000 non-null int64\n",
      "x013    100000 non-null int64\n",
      "x014    100000 non-null int64\n",
      "x015    100000 non-null int64\n",
      "x016    100000 non-null int64\n",
      "x017    100000 non-null int64\n",
      "x018    100000 non-null int64\n",
      "x019    100000 non-null int64\n",
      "x020    100000 non-null int64\n",
      "x021    100000 non-null int64\n",
      "x022    100000 non-null int64\n",
      "x023    100000 non-null int64\n",
      "x024    100000 non-null int64\n",
      "x025    100000 non-null int64\n",
      "x026    100000 non-null int64\n",
      "x027    100000 non-null int64\n",
      "x028    100000 non-null int64\n",
      "x029    100000 non-null int64\n",
      "x030    100000 non-null int64\n",
      "x031    100000 non-null int64\n",
      "x032    100000 non-null int64\n",
      "x033    100000 non-null int64\n",
      "x034    100000 non-null int64\n",
      "x035    100000 non-null int64\n",
      "x036    100000 non-null int64\n",
      "x037    100000 non-null int64\n",
      "x038    100000 non-null int64\n",
      "x039    100000 non-null int64\n",
      "x040    100000 non-null int64\n",
      "x041    63128 non-null float64\n",
      "x042    100000 non-null int64\n",
      "x043    100000 non-null int64\n",
      "x044    80326 non-null float64\n",
      "x045    80326 non-null float64\n",
      "x046    100000 non-null int64\n",
      "x047    100000 non-null int64\n",
      "x048    100000 non-null int64\n",
      "x049    100000 non-null int64\n",
      "x050    100000 non-null int64\n",
      "x051    100000 non-null int64\n",
      "x052    100000 non-null int64\n",
      "x053    100000 non-null int64\n",
      "x054    100000 non-null int64\n",
      "x055    100000 non-null int64\n",
      "x056    100000 non-null int64\n",
      "x057    63128 non-null float64\n",
      "x058    63128 non-null float64\n",
      "x059    100000 non-null int64\n",
      "x060    100000 non-null int64\n",
      "x061    100000 non-null int64\n",
      "x062    100000 non-null int64\n",
      "x063    100000 non-null int64\n",
      "x064    100000 non-null int64\n",
      "x065    100000 non-null int64\n",
      "x066    100000 non-null int64\n",
      "x067    100000 non-null int64\n",
      "x068    100000 non-null int64\n",
      "x069    100000 non-null int64\n",
      "x070    100000 non-null int64\n",
      "x071    100000 non-null int64\n",
      "x072    100000 non-null int64\n",
      "x073    100000 non-null int64\n",
      "x074    100000 non-null int64\n",
      "x075    100000 non-null int64\n",
      "x076    100000 non-null int64\n",
      "x077    100000 non-null int64\n",
      "x078    100000 non-null int64\n",
      "x079    100000 non-null int64\n",
      "x080    100000 non-null int64\n",
      "x081    100000 non-null int64\n",
      "x082    100000 non-null int64\n",
      "x083    100000 non-null int64\n",
      "x084    100000 non-null int64\n",
      "x085    100000 non-null int64\n",
      "x086    100000 non-null int64\n",
      "x087    100000 non-null int64\n",
      "x088    100000 non-null int64\n",
      "x089    100000 non-null int64\n",
      "x090    100000 non-null int64\n",
      "x091    100000 non-null int64\n",
      "x092    100000 non-null int64\n",
      "x093    100000 non-null int64\n",
      "x094    100000 non-null int64\n",
      "x095    100000 non-null int64\n",
      "x096    100000 non-null int64\n",
      "x097    100000 non-null int64\n",
      "x098    19319 non-null float64\n",
      "x099    100000 non-null int64\n",
      "x100    100000 non-null int64\n",
      "x101    100000 non-null int64\n",
      "x102    100000 non-null int64\n",
      "x103    100000 non-null int64\n",
      "x104    100000 non-null int64\n",
      "x105    100000 non-null int64\n",
      "x106    100000 non-null int64\n",
      "x107    100000 non-null int64\n",
      "x108    100000 non-null int64\n",
      "x109    100000 non-null int64\n",
      "x110    100000 non-null int64\n",
      "x111    100000 non-null int64\n",
      "x112    100000 non-null int64\n",
      "x113    100000 non-null int64\n",
      "x114    100000 non-null int64\n",
      "x115    100000 non-null int64\n",
      "x116    100000 non-null int64\n",
      "x117    100000 non-null int64\n",
      "x118    100000 non-null int64\n",
      "x119    100000 non-null int64\n",
      "x120    100000 non-null int64\n",
      "x121    100000 non-null int64\n",
      "x122    100000 non-null int64\n",
      "x123    100000 non-null int64\n",
      "x124    100000 non-null int64\n",
      "x125    100000 non-null int64\n",
      "x126    100000 non-null int64\n",
      "x127    100000 non-null int64\n",
      "x128    100000 non-null int64\n",
      "x129    100000 non-null int64\n",
      "x130    100000 non-null int64\n",
      "x131    100000 non-null int64\n",
      "x132    100000 non-null int64\n",
      "x133    100000 non-null int64\n",
      "x134    100000 non-null int64\n",
      "x135    100000 non-null int64\n",
      "x136    100000 non-null int64\n",
      "x137    100000 non-null int64\n",
      "x138    100000 non-null int64\n",
      "x139    100000 non-null int64\n",
      "x140    100000 non-null int64\n",
      "x141    100000 non-null int64\n",
      "x142    100000 non-null int64\n",
      "x143    100000 non-null int64\n",
      "x144    100000 non-null int64\n",
      "x145    100000 non-null int64\n",
      "x146    100000 non-null int64\n",
      "x147    100000 non-null int64\n",
      "x148    58215 non-null float64\n",
      "x149    100000 non-null int64\n",
      "x150    100000 non-null int64\n",
      "x151    100000 non-null int64\n",
      "x152    100000 non-null int64\n",
      "x153    100000 non-null int64\n",
      "x154    100000 non-null int64\n",
      "x155    20949 non-null float64\n",
      "x156    100000 non-null int64\n",
      "x157    100000 non-null int64\n",
      "x158    100000 non-null int64\n",
      "x159    100000 non-null int64\n",
      "x160    100000 non-null int64\n",
      "x161    100000 non-null int64\n",
      "x162    33519 non-null float64\n",
      "x163    100000 non-null int64\n",
      "x164    100000 non-null int64\n",
      "x165    100000 non-null int64\n",
      "x166    100000 non-null int64\n",
      "x167    100000 non-null int64\n",
      "x168    100000 non-null int64\n",
      "x169    100000 non-null int64\n",
      "x170    100000 non-null int64\n",
      "x171    100000 non-null int64\n",
      "x172    100000 non-null int64\n",
      "x173    100000 non-null int64\n",
      "x174    100000 non-null int64\n",
      "x175    100000 non-null int64\n",
      "x176    100000 non-null int64\n",
      "x177    100000 non-null int64\n",
      "x178    100000 non-null int64\n",
      "x179    100000 non-null int64\n",
      "x180    100000 non-null int64\n",
      "x181    100000 non-null int64\n",
      "x182    100000 non-null int64\n",
      "x183    100000 non-null int64\n",
      "x184    100000 non-null int64\n",
      "x185    100000 non-null int64\n",
      "x186    100000 non-null int64\n",
      "x187    100000 non-null int64\n",
      "x188    100000 non-null int64\n",
      "x189    100000 non-null int64\n",
      "x190    100000 non-null int64\n",
      "x191    100000 non-null int64\n",
      "x192    100000 non-null int64\n",
      "x193    100000 non-null int64\n",
      "x194    100000 non-null int64\n",
      "x195    100000 non-null int64\n",
      "x196    100000 non-null int64\n",
      "x197    100000 non-null int64\n",
      "x198    100000 non-null int64\n",
      "x199    100000 non-null int64\n",
      "x200    100000 non-null int64\n",
      "x201    100000 non-null int64\n",
      "x202    100000 non-null int64\n",
      "x203    100000 non-null int64\n",
      "x204    100000 non-null int64\n",
      "x205    100000 non-null int64\n",
      "x206    100000 non-null int64\n",
      "x207    100000 non-null int64\n",
      "x208    100000 non-null int64\n",
      "x209    100000 non-null int64\n",
      "x210    100000 non-null int64\n",
      "x211    100000 non-null int64\n",
      "x212    100000 non-null int64\n",
      "x213    100000 non-null int64\n",
      "x214    100000 non-null int64\n",
      "x215    100000 non-null int64\n",
      "x216    100000 non-null int64\n",
      "x217    100000 non-null int64\n",
      "x218    100000 non-null int64\n",
      "x219    100000 non-null int64\n",
      "x220    100000 non-null int64\n",
      "x221    100000 non-null int64\n",
      "x222    63013 non-null float64\n",
      "x223    62931 non-null float64\n",
      "x224    100000 non-null int64\n",
      "x225    100000 non-null int64\n",
      "x226    100000 non-null int64\n",
      "x227    100000 non-null int64\n",
      "x228    100000 non-null int64\n",
      "x229    100000 non-null int64\n",
      "x230    100000 non-null int64\n",
      "x231    100000 non-null int64\n",
      "x232    100000 non-null int64\n",
      "x233    100000 non-null int64\n",
      "x234    80890 non-null float64\n",
      "x235    79917 non-null float64\n",
      "x236    100000 non-null int64\n",
      "x237    63256 non-null float64\n",
      "x238    63256 non-null float64\n",
      "x239    63256 non-null float64\n",
      "x240    100000 non-null int64\n",
      "x241    100000 non-null int64\n",
      "x242    6661 non-null float64\n",
      "x243    100000 non-null int64\n",
      "x244    100000 non-null int64\n",
      "x245    100000 non-null int64\n",
      "x246    100000 non-null int64\n",
      "x247    100000 non-null int64\n",
      "x248    100000 non-null int64\n",
      "x249    100000 non-null int64\n",
      "x250    100000 non-null int64\n",
      "x251    100000 non-null int64\n",
      "x252    100000 non-null int64\n",
      "x253    33667 non-null float64\n",
      "x254    100000 non-null int64\n",
      "x255    23087 non-null float64\n",
      "x256    23087 non-null float64\n",
      "x257    23087 non-null float64\n",
      "x258    100000 non-null int64\n",
      "x259    22568 non-null float64\n",
      "x260    100000 non-null int64\n",
      "x261    100000 non-null int64\n",
      "x262    100000 non-null int64\n",
      "x263    100000 non-null int64\n",
      "x264    100000 non-null int64\n",
      "x265    33539 non-null float64\n",
      "x266    33539 non-null float64\n",
      "x267    33539 non-null float64\n",
      "x268    32747 non-null float64\n",
      "x269    100000 non-null int64\n",
      "x270    100000 non-null int64\n",
      "x271    100000 non-null int64\n",
      "x272    92811 non-null float64\n",
      "x273    100000 non-null int64\n",
      "x274    100000 non-null int64\n",
      "x275    43869 non-null float64\n",
      "x276    100000 non-null int64\n",
      "x277    100000 non-null int64\n",
      "x278    100000 non-null int64\n",
      "x279    100000 non-null int64\n",
      "x280    100000 non-null int64\n",
      "x281    100000 non-null int64\n",
      "x282    100000 non-null int64\n",
      "x283    100000 non-null int64\n",
      "x284    100000 non-null int64\n",
      "x285    100000 non-null int64\n",
      "x286    100000 non-null int64\n",
      "x287    75179 non-null float64\n",
      "x288    50244 non-null float64\n",
      "x289    50244 non-null float64\n",
      "x290    50244 non-null float64\n",
      "x291    100000 non-null int64\n",
      "x292    100000 non-null int64\n",
      "x293    48867 non-null float64\n",
      "x294    100000 non-null int64\n",
      "x295    13467 non-null float64\n",
      "x296    100000 non-null int64\n",
      "x297    41888 non-null float64\n",
      "x298    100000 non-null int64\n",
      "x299    100000 non-null int64\n",
      "x300    100000 non-null int64\n",
      "x301    100000 non-null int64\n",
      "x302    26931 non-null float64\n",
      "x303    100000 non-null int64\n",
      "x304    18125 non-null float64\n",
      "y       100000 non-null int64\n",
      "dtypes: float64(41), int64(264)\n",
      "memory usage: 233.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 19999\n",
      "Columns: 305 entries, x001 to y\n",
      "dtypes: float64(41), int64(264)\n",
      "memory usage: 233.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=['x017','x030','x065','x072','x105','x115','x120','x125','x127','x128','x129','x131','x135','x139','x141','x142','x143','x144','x146','x150','x152','x157','x159','x165','x167','x172','x173','x178','x179','x187','x188','x189','x191','x192','x195','x201','x203','x204','x206','x207','x208','x210','x212','x214','x216','x218','x219','x221','x223','x225','x227','x231','x246','x249','x250','x257','x261','x267','x270','x273','x276','x278','x281','x283','x290','x295','x297','x299','x067','x094','x095','x096','x073','x074','x116','x121','x137','x138','x140','x153','x160','x196','x202','x209','x213','x215','x237','x239','x247','x262','x271','x277','x279','x284','x300','x130','x220','x292']\n",
    "data.drop(columns=drop_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 207)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Missing Value Greater Than 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=['x304','x302','x293','x289','x288','x275','x268','x266','x265','x259','x256','x255','x253','x242','x238','x222',\n",
    "             'x162','x155','x148','x098','x058','x057','x293','x041']\n",
    "data.drop(columns=drop_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 184)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007', 'x008', 'x009',\n",
       "       'x010',\n",
       "       ...\n",
       "       'x285', 'x286', 'x287', 'x291', 'x294', 'x296', 'x298', 'x301', 'x303',\n",
       "       'y'],\n",
       "      dtype='object', length=184)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['x001'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x002,x003,x004,x005 columns are Positively skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x002\"].fillna(data[\"x002\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x003\"].fillna(data[\"x003\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x004\"].fillna(data[\"x004\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x005\"].fillna(data[\"x005\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x044\"].fillna(data[\"x044\"].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x045\"].fillna(data[\"x045\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x234\"].fillna(data[\"x234\"].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x235\"].fillna(data[\"x235\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x272\"].fillna(data[\"x272\"].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"x287\"].fillna(data[\"x287\"].mode()[0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 19999\n",
      "Data columns (total 183 columns):\n",
      "x002    100000 non-null float64\n",
      "x003    100000 non-null float64\n",
      "x004    100000 non-null float64\n",
      "x005    100000 non-null float64\n",
      "x006    100000 non-null int64\n",
      "x007    100000 non-null int64\n",
      "x008    100000 non-null int64\n",
      "x009    100000 non-null int64\n",
      "x010    100000 non-null int64\n",
      "x011    100000 non-null int64\n",
      "x012    100000 non-null int64\n",
      "x013    100000 non-null int64\n",
      "x014    100000 non-null int64\n",
      "x015    100000 non-null int64\n",
      "x016    100000 non-null int64\n",
      "x018    100000 non-null int64\n",
      "x019    100000 non-null int64\n",
      "x020    100000 non-null int64\n",
      "x021    100000 non-null int64\n",
      "x022    100000 non-null int64\n",
      "x023    100000 non-null int64\n",
      "x024    100000 non-null int64\n",
      "x025    100000 non-null int64\n",
      "x026    100000 non-null int64\n",
      "x027    100000 non-null int64\n",
      "x028    100000 non-null int64\n",
      "x029    100000 non-null int64\n",
      "x031    100000 non-null int64\n",
      "x032    100000 non-null int64\n",
      "x033    100000 non-null int64\n",
      "x034    100000 non-null int64\n",
      "x035    100000 non-null int64\n",
      "x036    100000 non-null int64\n",
      "x037    100000 non-null int64\n",
      "x038    100000 non-null int64\n",
      "x039    100000 non-null int64\n",
      "x040    100000 non-null int64\n",
      "x042    100000 non-null int64\n",
      "x043    100000 non-null int64\n",
      "x044    100000 non-null float64\n",
      "x045    100000 non-null float64\n",
      "x046    100000 non-null int64\n",
      "x047    100000 non-null int64\n",
      "x048    100000 non-null int64\n",
      "x049    100000 non-null int64\n",
      "x050    100000 non-null int64\n",
      "x051    100000 non-null int64\n",
      "x052    100000 non-null int64\n",
      "x053    100000 non-null int64\n",
      "x054    100000 non-null int64\n",
      "x055    100000 non-null int64\n",
      "x056    100000 non-null int64\n",
      "x059    100000 non-null int64\n",
      "x060    100000 non-null int64\n",
      "x061    100000 non-null int64\n",
      "x062    100000 non-null int64\n",
      "x063    100000 non-null int64\n",
      "x064    100000 non-null int64\n",
      "x066    100000 non-null int64\n",
      "x068    100000 non-null int64\n",
      "x069    100000 non-null int64\n",
      "x070    100000 non-null int64\n",
      "x071    100000 non-null int64\n",
      "x075    100000 non-null int64\n",
      "x076    100000 non-null int64\n",
      "x077    100000 non-null int64\n",
      "x078    100000 non-null int64\n",
      "x079    100000 non-null int64\n",
      "x080    100000 non-null int64\n",
      "x081    100000 non-null int64\n",
      "x082    100000 non-null int64\n",
      "x083    100000 non-null int64\n",
      "x084    100000 non-null int64\n",
      "x085    100000 non-null int64\n",
      "x086    100000 non-null int64\n",
      "x087    100000 non-null int64\n",
      "x088    100000 non-null int64\n",
      "x089    100000 non-null int64\n",
      "x090    100000 non-null int64\n",
      "x091    100000 non-null int64\n",
      "x092    100000 non-null int64\n",
      "x093    100000 non-null int64\n",
      "x097    100000 non-null int64\n",
      "x099    100000 non-null int64\n",
      "x100    100000 non-null int64\n",
      "x101    100000 non-null int64\n",
      "x102    100000 non-null int64\n",
      "x103    100000 non-null int64\n",
      "x104    100000 non-null int64\n",
      "x106    100000 non-null int64\n",
      "x107    100000 non-null int64\n",
      "x108    100000 non-null int64\n",
      "x109    100000 non-null int64\n",
      "x110    100000 non-null int64\n",
      "x111    100000 non-null int64\n",
      "x112    100000 non-null int64\n",
      "x113    100000 non-null int64\n",
      "x114    100000 non-null int64\n",
      "x117    100000 non-null int64\n",
      "x118    100000 non-null int64\n",
      "x119    100000 non-null int64\n",
      "x122    100000 non-null int64\n",
      "x123    100000 non-null int64\n",
      "x124    100000 non-null int64\n",
      "x126    100000 non-null int64\n",
      "x132    100000 non-null int64\n",
      "x133    100000 non-null int64\n",
      "x134    100000 non-null int64\n",
      "x136    100000 non-null int64\n",
      "x145    100000 non-null int64\n",
      "x147    100000 non-null int64\n",
      "x149    100000 non-null int64\n",
      "x151    100000 non-null int64\n",
      "x154    100000 non-null int64\n",
      "x156    100000 non-null int64\n",
      "x158    100000 non-null int64\n",
      "x161    100000 non-null int64\n",
      "x163    100000 non-null int64\n",
      "x164    100000 non-null int64\n",
      "x166    100000 non-null int64\n",
      "x168    100000 non-null int64\n",
      "x169    100000 non-null int64\n",
      "x170    100000 non-null int64\n",
      "x171    100000 non-null int64\n",
      "x174    100000 non-null int64\n",
      "x175    100000 non-null int64\n",
      "x176    100000 non-null int64\n",
      "x177    100000 non-null int64\n",
      "x180    100000 non-null int64\n",
      "x181    100000 non-null int64\n",
      "x182    100000 non-null int64\n",
      "x183    100000 non-null int64\n",
      "x184    100000 non-null int64\n",
      "x185    100000 non-null int64\n",
      "x186    100000 non-null int64\n",
      "x190    100000 non-null int64\n",
      "x193    100000 non-null int64\n",
      "x194    100000 non-null int64\n",
      "x197    100000 non-null int64\n",
      "x198    100000 non-null int64\n",
      "x199    100000 non-null int64\n",
      "x200    100000 non-null int64\n",
      "x205    100000 non-null int64\n",
      "x211    100000 non-null int64\n",
      "x217    100000 non-null int64\n",
      "x224    100000 non-null int64\n",
      "x226    100000 non-null int64\n",
      "x228    100000 non-null int64\n",
      "x229    100000 non-null int64\n",
      "x230    100000 non-null int64\n",
      "x232    100000 non-null int64\n",
      "x233    100000 non-null int64\n",
      "x234    100000 non-null float64\n",
      "x235    100000 non-null float64\n",
      "x236    100000 non-null int64\n",
      "x240    100000 non-null int64\n",
      "x241    100000 non-null int64\n",
      "x243    100000 non-null int64\n",
      "x244    100000 non-null int64\n",
      "x245    100000 non-null int64\n",
      "x248    100000 non-null int64\n",
      "x251    100000 non-null int64\n",
      "x252    100000 non-null int64\n",
      "x254    100000 non-null int64\n",
      "x258    100000 non-null int64\n",
      "x260    100000 non-null int64\n",
      "x263    100000 non-null int64\n",
      "x264    100000 non-null int64\n",
      "x269    100000 non-null int64\n",
      "x272    100000 non-null float64\n",
      "x274    100000 non-null int64\n",
      "x280    100000 non-null int64\n",
      "x282    100000 non-null int64\n",
      "x285    100000 non-null int64\n",
      "x286    100000 non-null int64\n",
      "x287    100000 non-null float64\n",
      "x291    100000 non-null int64\n",
      "x294    100000 non-null int64\n",
      "x296    100000 non-null int64\n",
      "x298    100000 non-null int64\n",
      "x301    100000 non-null int64\n",
      "x303    100000 non-null int64\n",
      "y       100000 non-null int64\n",
      "dtypes: float64(10), int64(173)\n",
      "memory usage: 140.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorartory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "corr_result=pd.DataFrame(data[data.columns[1:]].corr()['y'][:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x002 0.4689602247914201\n",
      "x003 0.16795639856268593\n",
      "x004 0.41818507241409303\n",
      "x005 0.5729257045894965\n",
      "x006 0.09214381702297549\n",
      "x007 0.008622644375465796\n",
      "x008 -0.02192000049984312\n",
      "x009 -0.0015218572363849916\n",
      "x010 0.04365350422033073\n",
      "x011 0.11311063173901759\n",
      "x012 0.11755835818544343\n",
      "x013 0.1781628123399855\n",
      "x014 0.47434247497310805\n",
      "x015 0.30884224553895484\n",
      "x016 0.19417175079948346\n",
      "x018 0.41046217683451697\n",
      "x019 0.4132837884376316\n",
      "x020 0.4156879660656005\n",
      "x021 0.24280364327524007\n",
      "x022 0.5688841954308335\n",
      "x023 0.48063920134477306\n",
      "x024 -0.059220687575074794\n",
      "x025 0.4873764961489122\n",
      "x026 0.2125082722263131\n",
      "x027 0.42420611785102147\n",
      "x028 0.4147597589645361\n",
      "x029 0.2178318476037858\n",
      "x031 -0.2800987212723916\n",
      "x032 -0.07771866302967714\n",
      "x033 -0.11286844474446285\n",
      "x034 -0.1916940682258981\n",
      "x035 -0.25484206741708915\n",
      "x036 -0.31205465151322226\n",
      "x037 -0.09127003239733891\n",
      "x038 -0.12503725781646266\n",
      "x039 -0.2165530122050227\n",
      "x040 -0.2917141169098679\n",
      "x042 0.29336312577587936\n",
      "x043 0.3684458764992495\n",
      "x044 0.18938244963218456\n",
      "x045 0.16518326635216377\n",
      "x046 0.507595317008764\n",
      "x047 0.30698709954147996\n",
      "x048 0.19502679279016683\n",
      "x049 0.13728249005479157\n",
      "x050 0.09611403873043528\n",
      "x051 0.05974262144431227\n",
      "x052 0.029611797843836815\n",
      "x053 0.012722409846928146\n",
      "x054 -0.022509729053687685\n",
      "x055 -0.0919109884748103\n",
      "x056 -0.33656655789795115\n",
      "x059 -0.41502886399080263\n",
      "x060 -0.0019726756373270723\n",
      "x061 -0.17737204013540694\n",
      "x062 -0.29397355468455044\n",
      "x063 -0.3584498381590801\n",
      "x064 -0.41110104519022966\n",
      "x066 -0.21232657113779563\n",
      "x068 -0.05988740086211346\n",
      "x069 -0.10687941514650856\n",
      "x070 -0.13807412106934952\n",
      "x071 -0.1833385880860633\n",
      "x075 -0.26067723941617976\n",
      "x076 -0.19241637936825826\n",
      "x077 -0.04702829985363517\n",
      "x078 -0.09093019245271355\n",
      "x079 -0.11362828401878747\n",
      "x080 -0.16111039001008667\n",
      "x081 -0.178198003658794\n",
      "x082 -0.08865057750741366\n",
      "x083 -0.03957432044865944\n",
      "x084 -0.03373795143956146\n",
      "x085 -0.04179852301750046\n",
      "x086 -0.06829890712421888\n",
      "x087 -0.07856345755525707\n",
      "x088 -0.08127442616536841\n",
      "x089 -0.2292524040442547\n",
      "x090 -0.07125882159313691\n",
      "x091 -0.10510214149606495\n",
      "x092 -0.050870680203497914\n",
      "x093 -0.02635036082075796\n",
      "x097 -0.1916696242261413\n",
      "x099 -0.3074276685564601\n",
      "x100 -0.20366873271682764\n",
      "x101 -0.18904404191452415\n",
      "x102 -0.12897786682849782\n",
      "x103 -0.18440507563864328\n",
      "x104 -0.26394338836089154\n",
      "x106 -0.2574985371413662\n",
      "x107 -0.08761980488813628\n",
      "x108 -0.17634039162463633\n",
      "x109 -0.11511990783495855\n",
      "x110 -0.19035176915239815\n",
      "x111 -0.21292694977264273\n",
      "x112 -0.26233460154134236\n",
      "x113 -0.2451613153709934\n",
      "x114 -0.21254090337911005\n",
      "x117 -0.25665248654122974\n",
      "x118 -0.24991718766012647\n",
      "x119 -0.237546048144427\n",
      "x122 -0.2183411294956285\n",
      "x123 -0.2116397084398944\n",
      "x124 -0.1916819063687819\n",
      "x126 -0.1651644079275415\n",
      "x132 -0.16109149080831608\n",
      "x133 -0.1795903816883683\n",
      "x134 -0.17794363143724912\n",
      "x136 -0.16745412732706128\n",
      "x145 -0.15264871785456724\n",
      "x147 -0.26175488895467564\n",
      "x149 -0.20805976889931332\n",
      "x151 -0.1779744025682349\n",
      "x154 -0.08042477889813834\n",
      "x156 -0.07735041458381445\n",
      "x158 -0.07310337190937329\n",
      "x161 -0.17863044850721121\n",
      "x163 -0.16577274577590628\n",
      "x164 -0.15629462654983464\n",
      "x166 -0.13231243721127503\n",
      "x168 -0.3480830246109153\n",
      "x169 -0.2204775337675138\n",
      "x170 -0.24655211625211257\n",
      "x171 -0.2837627049226483\n",
      "x174 -0.24420234483533088\n",
      "x175 -0.1573007613138074\n",
      "x176 -0.18186099816747883\n",
      "x177 -0.2068096607585717\n",
      "x180 -0.11742967006963026\n",
      "x181 -0.25821791996648263\n",
      "x182 -0.04187252548734809\n",
      "x183 -0.15621865995722944\n",
      "x184 -0.13472304267929605\n",
      "x185 -0.2304783463963402\n",
      "x186 -0.2358072595964385\n",
      "x190 -0.19511971321815302\n",
      "x193 -0.2700205230008831\n",
      "x194 -0.2597150281966188\n",
      "x197 -0.2289010687368766\n",
      "x198 -0.22971850958906556\n",
      "x199 -0.2150486404349642\n",
      "x200 -0.2015071415507178\n",
      "x205 -0.21783002422059394\n",
      "x211 -0.20465199944920784\n",
      "x217 -0.1506611550424416\n",
      "x224 0.4325310567161606\n",
      "x226 0.5140545911659086\n",
      "x228 0.5120672395238398\n",
      "x229 0.44327910008580923\n",
      "x230 0.05898012698387029\n",
      "x232 -0.0008258762498767463\n",
      "x233 0.1251328785424378\n",
      "x234 0.10595291166546868\n",
      "x235 0.6142618257530863\n",
      "x236 0.5728754020041867\n",
      "x240 -0.2647046571661699\n",
      "x241 -0.23233812363004216\n",
      "x243 -0.12760766160704626\n",
      "x244 0.5033209804805688\n",
      "x245 0.46773480962759467\n",
      "x248 0.3830710568346825\n",
      "x251 0.3764008183498883\n",
      "x252 -0.07867878287030368\n",
      "x254 -0.009714455164365731\n",
      "x258 0.24287985089886566\n",
      "x260 0.43492047914335424\n",
      "x263 0.13536553830540435\n",
      "x264 0.11523782948209867\n",
      "x269 0.062477669320403155\n",
      "x272 -0.06477732428261734\n",
      "x274 -0.13315368030839037\n",
      "x280 -0.06666999094970567\n",
      "x282 0.2973338457477155\n",
      "x285 -0.060159773154616326\n",
      "x286 -0.20247570421604966\n",
      "x287 -0.43168779339621066\n",
      "x291 0.04215867773816459\n",
      "x294 -0.1123543718004514\n",
      "x296 0.11027780498731468\n",
      "x298 -0.04432932510180197\n",
      "x301 -0.22448378184470455\n",
      "x303 -0.035370218323335256\n",
      "y 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns[0:]:\n",
    "    print(i, data[i].corr(data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>x010</th>\n",
       "      <th>x011</th>\n",
       "      <th>...</th>\n",
       "      <th>x285</th>\n",
       "      <th>x286</th>\n",
       "      <th>x287</th>\n",
       "      <th>x291</th>\n",
       "      <th>x294</th>\n",
       "      <th>x296</th>\n",
       "      <th>x298</th>\n",
       "      <th>x301</th>\n",
       "      <th>x303</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>x002</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x003</td>\n",
       "      <td>0.308</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x004</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.711</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x005</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x006</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.131</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x296</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x298</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.334</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x301</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x303</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>y</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows Ã— 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x002   x003   x004   x005   x006   x007   x008   x009   x010   x011  \\\n",
       "x002  1.000  0.308  0.833  0.718  0.107 -0.099 -0.120 -0.052  0.003  0.066   \n",
       "x003  0.308  1.000  0.711  0.248  0.212 -0.206 -0.226 -0.155 -0.119 -0.097   \n",
       "x004  0.833  0.711  1.000  0.612  0.202 -0.228 -0.263 -0.171 -0.105 -0.038   \n",
       "x005  0.718  0.248  0.612  1.000  0.131 -0.048 -0.062 -0.015  0.034  0.106   \n",
       "x006  0.107  0.212  0.202  0.131  1.000 -0.129 -0.112 -0.007  0.026  0.056   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "x296  0.072 -0.101 -0.026  0.067 -0.022  0.160  0.188  0.198  0.201  0.241   \n",
       "x298 -0.072 -0.185 -0.179 -0.051 -0.008  0.215  0.269  0.282  0.277  0.287   \n",
       "x301 -0.072 -0.010 -0.049 -0.092 -0.004  0.003  0.008  0.016  0.022  0.076   \n",
       "x303  0.021 -0.038 -0.004 -0.009 -0.009  0.091  0.105  0.126  0.143  0.213   \n",
       "y     0.469  0.168  0.418  0.573  0.092  0.009 -0.022 -0.002  0.044  0.113   \n",
       "\n",
       "      ...   x285   x286   x287   x291   x294   x296   x298   x301   x303  \\\n",
       "x002  ... -0.007 -0.048 -0.184  0.059 -0.004  0.072 -0.072 -0.072  0.021   \n",
       "x003  ... -0.111 -0.002 -0.033 -0.089 -0.005 -0.101 -0.185 -0.010 -0.038   \n",
       "x004  ... -0.068 -0.029 -0.143 -0.023 -0.001 -0.026 -0.179 -0.049 -0.004   \n",
       "x005  ... -0.048 -0.063 -0.212  0.050 -0.015  0.067 -0.051 -0.092 -0.009   \n",
       "x006  ... -0.015  0.027  0.032 -0.012  0.014 -0.022 -0.008 -0.004 -0.009   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "x296  ...  0.452 -0.015 -0.020  0.886  0.066  1.000  0.334  0.088  0.609   \n",
       "x298  ...  0.461  0.141  0.312  0.353  0.145  0.334  1.000  0.147  0.242   \n",
       "x301  ...  0.237  0.261  0.351  0.151  0.163  0.088  0.147  1.000  0.260   \n",
       "x303  ...  0.578  0.122  0.108  0.688  0.360  0.609  0.242  0.260  1.000   \n",
       "y     ... -0.060 -0.202 -0.432  0.042 -0.112  0.110 -0.044 -0.224 -0.035   \n",
       "\n",
       "          y  \n",
       "x002  0.469  \n",
       "x003  0.168  \n",
       "x004  0.418  \n",
       "x005  0.573  \n",
       "x006  0.092  \n",
       "...     ...  \n",
       "x296  0.110  \n",
       "x298 -0.044  \n",
       "x301 -0.224  \n",
       "x303 -0.035  \n",
       "y     1.000  \n",
       "\n",
       "[183 rows x 183 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unrelated and weak relationship 05 to -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeValue = [];\n",
    "for i in data.columns[0:]:\n",
    "    if (data[i].corr(data['y']) <= 0.1 and data[i].corr(data['y']) >= -0.1):\n",
    "        removeValue.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##plt.figure(figsize=(25,10))\n",
    "##sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=removeValue,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 139)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x011</th>\n",
       "      <th>x012</th>\n",
       "      <th>x013</th>\n",
       "      <th>x014</th>\n",
       "      <th>x015</th>\n",
       "      <th>x016</th>\n",
       "      <th>...</th>\n",
       "      <th>x263</th>\n",
       "      <th>x264</th>\n",
       "      <th>x274</th>\n",
       "      <th>x282</th>\n",
       "      <th>x286</th>\n",
       "      <th>x287</th>\n",
       "      <th>x294</th>\n",
       "      <th>x296</th>\n",
       "      <th>x301</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>x002</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x003</td>\n",
       "      <td>0.308</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x004</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.711</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x005</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x011</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x287</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x294</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.163</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x296</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x301</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>y</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x002   x003   x004   x005   x011   x012   x013   x014   x015   x016  \\\n",
       "x002  1.000  0.308  0.833  0.718  0.066  0.098  0.158  0.518  0.276  0.235   \n",
       "x003  0.308  1.000  0.711  0.248 -0.097 -0.056 -0.025  0.073 -0.092 -0.151   \n",
       "x004  0.833  0.711  1.000  0.612 -0.038  0.021  0.087  0.396  0.102  0.040   \n",
       "x005  0.718  0.248  0.612  1.000  0.106  0.132  0.200  0.613  0.367  0.202   \n",
       "x011  0.066 -0.097 -0.038  0.106  1.000  0.480  0.320  0.245  0.664  0.451   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "x287 -0.184 -0.033 -0.143 -0.212  0.108  0.141  0.090 -0.116  0.046 -0.045   \n",
       "x294 -0.004 -0.005 -0.001 -0.015  0.077  0.112  0.103  0.059  0.111  0.146   \n",
       "x296  0.072 -0.101 -0.026  0.067  0.241  0.238  0.236  0.220  0.357  0.414   \n",
       "x301 -0.072 -0.010 -0.049 -0.092  0.076  0.210  0.203  0.019  0.123  0.076   \n",
       "y     0.469  0.168  0.418  0.573  0.113  0.118  0.178  0.474  0.309  0.194   \n",
       "\n",
       "      ...   x263   x264   x274  x282   x286   x287   x294   x296   x301      y  \n",
       "x002  ...  0.021  0.042  0.009 0.077 -0.048 -0.184 -0.004  0.072 -0.072  0.469  \n",
       "x003  ... -0.177 -0.154  0.033 0.074 -0.002 -0.033 -0.005 -0.101 -0.010  0.168  \n",
       "x004  ... -0.112 -0.090  0.023 0.073 -0.029 -0.143 -0.001 -0.026 -0.049  0.418  \n",
       "x005  ...  0.076  0.076  0.020 0.167 -0.063 -0.212 -0.015  0.067 -0.092  0.573  \n",
       "x011  ...  0.237  0.220  0.034 0.222  0.098  0.108  0.077  0.241  0.076  0.113  \n",
       "...   ...    ...    ...    ...   ...    ...    ...    ...    ...    ...    ...  \n",
       "x287  ...  0.023 -0.009  0.135 0.078  0.195  1.000  0.155 -0.020  0.351 -0.432  \n",
       "x294  ...  0.095  0.095  0.134 0.062  0.225  0.155  1.000  0.066  0.163 -0.112  \n",
       "x296  ...  0.318  0.458  0.003 0.144 -0.015 -0.020  0.066  1.000  0.088  0.110  \n",
       "x301  ...  0.002 -0.013  0.066 0.012  0.261  0.351  0.163  0.088  1.000 -0.224  \n",
       "y     ...  0.135  0.115 -0.133 0.297 -0.202 -0.432 -0.112  0.110 -0.224  1.000  \n",
       "\n",
       "[139 rows x 139 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('Credit_Score_Prediction.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=data.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 138)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x011</th>\n",
       "      <th>x012</th>\n",
       "      <th>x013</th>\n",
       "      <th>x014</th>\n",
       "      <th>x015</th>\n",
       "      <th>x016</th>\n",
       "      <th>...</th>\n",
       "      <th>x260</th>\n",
       "      <th>x263</th>\n",
       "      <th>x264</th>\n",
       "      <th>x274</th>\n",
       "      <th>x282</th>\n",
       "      <th>x286</th>\n",
       "      <th>x287</th>\n",
       "      <th>x294</th>\n",
       "      <th>x296</th>\n",
       "      <th>x301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>426.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>128.000</td>\n",
       "      <td>426.000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>160.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>160.000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>163.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>239.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>102.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17413</td>\n",
       "      <td>21424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x002   x003    x004    x005  x011  x012  x013  x014  x015  x016  ...  \\\n",
       "0 426.000 39.000 128.000 426.000     2     4     4     9    19     5  ...   \n",
       "1 160.000  2.000  64.000 160.000     3     3     7     5    21     5  ...   \n",
       "2 163.000 16.000 104.000 239.000     1     0     0     6     8     3  ...   \n",
       "3 100.000  8.000  48.000 102.000     0     2     2     0     4     0  ...   \n",
       "4   3.000  2.000   2.000  62.000     1     2     0     0     5     2  ...   \n",
       "\n",
       "   x260  x263   x264   x274  x282  x286  x287  x294   x296  x301  \n",
       "0     1     0      0      0     1     0 1.000     0      0     0  \n",
       "1     1     1  17318      0     1     0 1.000     0  17318     0  \n",
       "2     0     0      0      0     1     0 1.000     0      0     0  \n",
       "3     0     0      0    619     1     0 9.000     0      0     0  \n",
       "4     0     1  17413  21424     1     0 9.000     0  17413     0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 138)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 138)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train=[];\n",
    "rmse_test=[];\n",
    "model_name=[];\n",
    "def modeling(model,x_train,x_test,y_train,y_test,name):\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_predicated=model.predict(x_train);\n",
    "    train_error=np.sqrt(mean_squared_error(y_train,y_train_predicated));\n",
    "    print(train_error)\n",
    "    y_test_predicated=model.predict(x_test);\n",
    "    test_error=np.sqrt(mean_squared_error(y_test,y_test_predicated))\n",
    "    print(test_error)\n",
    "    rmse_train.append(train_error)\n",
    "    rmse_test.append(test_error)\n",
    "    model_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.790786748384875\n",
      "52.75256365655211\n"
     ]
    }
   ],
   "source": [
    "modeling(linear,x_train,x_test,y_train,y_test,'LinearRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=10,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.25614269215681\n",
      "118.93903155719204\n"
     ]
    }
   ],
   "source": [
    "modeling(lasso,x_train,x_test,y_train,y_test,'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.79078829985354\n",
      "52.75252473503327\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "modeling(ridge,x_train,x_test,y_train,y_test,'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.720276806309755\n",
      "55.734975123185706\n"
     ]
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=0.4,l1_ratio=0.5)\n",
    "modeling(elastic,x_train,x_test,y_train,y_test,'elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.2266016755228\n",
      "50.81145822471138\n"
     ]
    }
   ],
   "source": [
    "adaBoost = AdaBoostRegressor()\n",
    "modeling(adaBoost,x_train,x_test,y_train,y_test,'AdaBoostRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.858063352107745\n",
      "32.54163957290094\n"
     ]
    }
   ],
   "source": [
    "random = RandomForestRegressor()\n",
    "modeling(random,x_train,x_test,y_train,y_test,'RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.77146801643276\n",
      "34.57225873106589\n"
     ]
    }
   ],
   "source": [
    "gradientBoosting = GradientBoostingRegressor()\n",
    "modeling(gradientBoosting,x_train,x_test,y_train,y_test,'GradientBoostingRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.75592772667364\n",
      "34.570071776524934\n"
     ]
    }
   ],
   "source": [
    "xgBoost=xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "modeling(xgBoost,x_train,x_test,y_train,y_test,'xgBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.325486349419112\n",
      "30.14822476506468\n"
     ]
    }
   ],
   "source": [
    "lgb=LGBMRegressor()\n",
    "modeling(lgb,x_train,x_test,y_train,y_test,'LGBMRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##svm=LinearSVR()\n",
    "##modeling(svm,x_train,x_test,y_train,y_test,'LinearSVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalResult():\n",
    "    result = pd.DataFrame([model_name,rmse_train,rmse_test]).T\n",
    "    result.columns = [\"Model_Name\", \"Train\", \"Test\"]\n",
    "    result.to_excel('Model.xlsx',index=False)\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = finalResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>13.858</td>\n",
       "      <td>32.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>28.325</td>\n",
       "      <td>30.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>xgBoost</td>\n",
       "      <td>33.756</td>\n",
       "      <td>34.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>33.771</td>\n",
       "      <td>34.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>50.227</td>\n",
       "      <td>50.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>51.791</td>\n",
       "      <td>52.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>51.791</td>\n",
       "      <td>52.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>elastic</td>\n",
       "      <td>54.720</td>\n",
       "      <td>55.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>118.256</td>\n",
       "      <td>118.939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model_Name   Train    Test\n",
       "5      RandomForestRegressor  13.858  32.542\n",
       "8              LGBMRegressor  28.325  30.148\n",
       "7                    xgBoost  33.756  34.570\n",
       "6  GradientBoostingRegressor  33.771  34.572\n",
       "4          AdaBoostRegressor  50.227  50.811\n",
       "0           LinearRegression  51.791  52.753\n",
       "2                      Ridge  51.791  52.753\n",
       "3                    elastic  54.720  55.735\n",
       "1                      Lasso 118.256 118.939"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='Train', ascending=True, na_position='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperTunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Various learning rate parameters\n",
    "learning_rate = ['0.05','0.1', '0.2','0.3','0.5','0.6']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "#Subssample parameter values\n",
    "subsample=[0.7,0.6,0.8]\n",
    "# Minimum child weight parameters\n",
    "min_child_weight=[3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200], 'learning_rate': ['0.05', '0.1', '0.2', '0.3', '0.5', '0.6'], 'max_depth': [5, 10, 15, 20, 25, 30], 'subsample': [0.7, 0.6, 0.8], 'min_child_weight': [3, 4, 5, 6, 7]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'subsample': subsample,\n",
    "               'min_child_weight': min_child_weight}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "regressor=xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search across 100 different combinations\n",
    "xg_random = RandomizedSearchCV(estimator = regressor, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:29:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3, total=16.9min\n",
      "[CV] subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:46:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3, total=17.6min\n",
      "[CV] subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[09:03:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3, total=27.4min\n",
      "[CV] subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[09:31:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3, total=38.9min\n",
      "[CV] subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3 \n",
      "[10:09:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1100, min_child_weight=6, max_depth=10, learning_rate=0.3, total=30.7min\n",
      "[CV] subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[10:40:41] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3, total=37.5min\n",
      "[CV] subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[11:18:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3, total=37.2min\n",
      "[CV] subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[11:55:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3, total=25.0min\n",
      "[CV] subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[12:20:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3, total=21.5min\n",
      "[CV] subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3 \n",
      "[12:41:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=600, min_child_weight=6, max_depth=20, learning_rate=0.3, total=20.9min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1 \n",
      "[13:02:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1, total=28.3min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1 \n",
      "[13:31:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1, total=29.7min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1 \n",
      "[14:00:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1, total=28.4min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1 \n",
      "[14:29:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1, total=27.6min\n",
      "[CV] subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1 \n",
      "[14:56:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=300, min_child_weight=7, max_depth=30, learning_rate=0.1, total=26.0min\n",
      "[CV] subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05 \n",
      "[15:22:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05, total=17.9min\n",
      "[CV] subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05 \n",
      "[15:40:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05, total=16.3min\n",
      "[CV] subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05 \n",
      "[15:56:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05, total=22.3min\n",
      "[CV] subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05 \n",
      "[16:19:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05, total=28.0min\n",
      "[CV] subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05 \n",
      "[16:47:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=1000, min_child_weight=7, max_depth=10, learning_rate=0.05, total=17.8min\n",
      "[CV] subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3 \n",
      "[17:04:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3, total= 2.0min\n",
      "[CV] subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3 \n",
      "[17:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3, total= 2.0min\n",
      "[CV] subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3 \n",
      "[17:08:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3 \n",
      "[17:10:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3, total= 1.7min\n",
      "[CV] subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.8, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.3, total= 1.8min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[17:14:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3, total= 4.7min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[17:18:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3, total= 4.4min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[17:23:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3, total= 4.4min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[17:27:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3, total= 4.4min\n",
      "[CV] subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3 \n",
      "[17:32:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=500, min_child_weight=6, max_depth=5, learning_rate=0.3, total= 4.7min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2 \n",
      "[17:36:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2, total= 4.5min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2 \n",
      "[17:41:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2, total= 4.3min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2 \n",
      "[17:45:31] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2, total= 4.5min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2 \n",
      "[17:50:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2, total= 4.6min\n",
      "[CV] subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2 \n",
      "[17:54:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=100, min_child_weight=7, max_depth=25, learning_rate=0.2, total= 4.8min\n",
      "[CV] subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1 \n",
      "[17:59:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1, total=17.3min\n",
      "[CV] subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1 \n",
      "[18:16:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1, total=17.8min\n",
      "[CV] subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1 \n",
      "[18:34:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1, total=17.2min\n",
      "[CV] subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1 \n",
      "[18:51:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1, total=17.3min\n",
      "[CV] subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1 \n",
      "[19:09:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.6, n_estimators=900, min_child_weight=5, max_depth=10, learning_rate=0.1, total=17.5min\n",
      "[CV] subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3 \n",
      "[19:26:32] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3, total=14.8min\n",
      "[CV] subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3 \n",
      "[19:41:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3, total=14.5min\n",
      "[CV] subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3 \n",
      "[19:55:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[CV]  subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3, total=14.1min\n",
      "[CV] subsample=0.7, n_estimators=500, min_child_weight=6, max_depth=15, learning_rate=0.3 \n",
      "[20:10:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f6e3a51a5a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxg_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xg_random.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-0db950519a62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxg_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "xg_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
